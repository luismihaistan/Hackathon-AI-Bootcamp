import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from sklearn.preprocessing import StandardScaler
import joblib
import os

# --- 1. GENERARE DATE SINTETICE (AceeaÈ™i ca Ã®nainte) ---
def genereaza_dataset_fictiv(n_rows=20000):
    print(f"â³ Generare dataset cu {n_rows} de tranzacÈ›ii...")
    np.random.seed(42)
    
    data = {
        'amount': np.round(np.random.uniform(0.5, 50.0, n_rows), 2),
        'hour': np.random.randint(0, 24, n_rows),
        'merchant_risk_score': np.random.uniform(0, 1, n_rows),
        'is_international': np.random.choice([0, 1], n_rows, p=[0.9, 0.1]),
        'transaction_velocity': np.random.randint(0, 20, n_rows)
    }
    
    df = pd.DataFrame(data)
    
    # LogicÄƒ de fraudÄƒ (puÈ›in mai complexÄƒ)
    def simulate_fraud(row):
        risk = 0
        # Regulile 'secrete' pe care AI-ul trebuie sÄƒ le ghiceascÄƒ
        if row['transaction_velocity'] > 12: risk += 0.45
        if row['merchant_risk_score'] > 0.75: risk += 0.25
        if row['is_international'] == 1: risk += 0.15
        if row['hour'] < 5: risk += 0.20
        
        return 1 if (risk + np.random.uniform(0, 0.15)) > 0.85 else 0

    df['is_fraud'] = df.apply(simulate_fraud, axis=1)
    print(f"âœ… Dataset gata. RatÄƒ fraudÄƒ: {df['is_fraud'].mean()*100:.2f}%")
    return df

# --- 2. PREPROCESARE ---
def preprocesare_date(df):
    X = df.drop(['is_fraud'], axis=1)
    y = df['is_fraud']
    
    # PÄƒstrÄƒm numele coloanelor pentru raportul final
    feature_names = X.columns.tolist()
    
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    return X_scaled, y, scaler, feature_names

# --- 3. ANTRENARE È˜I RAPORTARE DETALIATÄ‚ ---
def antreneaza_model():
    # A. PregÄƒtire
    df = genereaza_dataset_fictiv()
    X, y, scaler, feature_names = preprocesare_date(df)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    # B. Model
    print("\nğŸ§  Antrenare model Random Forest (optimizat pentru fraude)...")
    model = RandomForestClassifier(
        n_estimators=200, 
        max_depth=12, 
        random_state=42, 
        class_weight='balanced',
        n_jobs=-1
    )
    model.fit(X_train, y_train)
    
    # C. PredicÈ›ii
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1] # Probabilitatea de a fi fraudÄƒ (0.0 la 1.0)
    
    print("\n" + "="*40)
    print("      RAPORT DETALIAT DE PERFORMANÈšÄ‚")
    print("="*40)

    # --- ANALIZA 1: ImportanÈ›a Caracteristicilor ---
    # Ce conteazÄƒ cel mai mult pentru model?
    importances = model.feature_importances_
    indices = np.argsort(importances)[::-1]
    
    print("\nğŸ“Š CEI MAI IMPORTANÈšI FACTORI DE RISC:")
    print("-" * 40)
    print(f"{'Factor (Feature)':<25} | {'ImportanÈ›Äƒ (%)':<15}")
    print("-" * 40)
    for f in range(X.shape[1]):
        feat_name = feature_names[indices[f]]
        score = importances[indices[f]] * 100
        print(f"{feat_name:<25} | {score:.2f}%")
    print("-" * 40)
    print("Interpretabilitate: Factorul de sus este cel la care AI-ul se uitÄƒ primul.")

    # --- ANALIZA 2: PerformanÈ›a StatisticÄƒ ---
    print("\nğŸ“ˆ METRICI CHEIE:")
    roc_score = roc_auc_score(y_test, y_prob)
    print(f"Scor ROC-AUC: {roc_score:.4f} (1.0 = Perfect, 0.5 = Ghicit)")
    if roc_score > 0.9: print("   -> Calificativ: EXCELENT")
    elif roc_score > 0.8: print("   -> Calificativ: BUN")
    else: print("   -> Calificativ: NECESITÄ‚ ÃMBUNÄ‚TÄ‚ÈšIRI")

    # --- ANALIZA 3: Confuzie explicatÄƒ ---
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    print("\nğŸ” REALITATEA DIN TEREN (Matricea de Confuzie):")
    print(f"âœ… TranzacÈ›ii OK permise:     {tn} (ClienÈ›i fericiÈ›i)")
    print(f"âŒ Alarme False (Blocaje):    {fp} (ClienÈ›i deranjaÈ›i)")
    print(f"âš ï¸ Fraude SCÄ‚PATE:            {fn} (Pierdere bani)")
    print(f"ğŸ›¡ï¸ Fraude OPRITE:             {tp} (Bani salvaÈ›i)")

    # --- ANALIZA 4: Exemple Concrete ---
    print("\nğŸ’¡ EXEMPLE DE TRANZACÈšII ANALIZATE ACUM:")
    # LuÄƒm 5 exemple din test set
    test_indices = np.random.choice(len(X_test), 5, replace=False)
    print(f"{'VitezÄƒ':<10} {'ScorRisk':<10} {'OrÄƒ':<5} {'Intl?':<5} | {'REAL':<5} -> {'PREZIS (Prob %)':<15}")
    
    X_test_original = scaler.inverse_transform(X_test) # Revenim la valorile normale pentru afiÈ™are
    
    for i in test_indices:
        row = X_test_original[i]
        real_val = "FRAUDÄ‚" if y_test.iloc[i] == 1 else "OK"
        pred_val = "FRAUDÄ‚" if y_pred[i] == 1 else "OK"
        prob_fraud = y_prob[i] * 100
        
        # Extragem valorile pentru afiÈ™are
        vel = int(row[4]) # velocity e pe index 4 in X_test
        risk = f"{row[2]:.2f}" # merchant risk
        hour = int(row[1])
        intl = "DA" if row[3] > 0.5 else "NU"
        
        print(f"{vel:<10} {risk:<10} {hour:<5} {intl:<5} | {real_val:<5} -> {pred_val} ({prob_fraud:.1f}%)")

    # Salvare
    if not os.path.exists('models'): os.makedirs('models')
    joblib.dump(model, 'models/fraud_model.pkl')
    joblib.dump(scaler, 'models/scaler.pkl')
    print("\nğŸ’¾ Model salvat.")

if __name__ == "__main__":
    antreneaza_model()