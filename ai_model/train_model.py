import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
import joblib
import os

# --- CONFIGURARE CÄ‚I (PATHS) ---
current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(current_dir)

DATA_PATH = os.path.join(root_dir, "data", "transactions_micro_extended.csv")
MODELS_DIR = os.path.join(root_dir, "models")

# 1. ÃNCÄ‚RCARE DATE DIN CSV
def incarca_date():
    print(f"ğŸ“‚ CÄƒutÄƒm fiÈ™ierul la: {DATA_PATH}")
    if not os.path.exists(DATA_PATH):
        raise FileNotFoundError(f"âŒ Nu am gÄƒsit fiÈ™ierul la: {DATA_PATH}")

    df = pd.read_csv(DATA_PATH)

    # Facem coloana target consistentÄƒ
    if "is_fraud" not in df.columns:
        if "Class" in df.columns:
            df.rename(columns={"Class": "is_fraud"}, inplace=True)
        else:
            raise ValueError("âŒ CSV-ul nu are 'is_fraud' sau 'Class'.")

    LIMITA_MICRO = 100.0
    print(f"ğŸ“Š Total tranzacÈ›ii iniÈ›iale: {len(df)}")
    print(f"ğŸ’° Suma maximÄƒ: {df['Amount'].max()}")

    df = df[df["Amount"] <= LIMITA_MICRO].copy()

    print(f"âœ‚ï¸ Filtru micro-tranzacÈ›ii (<= {LIMITA_MICRO})")
    print(f"âœ… TranzacÈ›ii rÄƒmase: {len(df)}")
    print(f"Fraude Ã®n datele filtrate: {df['is_fraud'].mean()*100:.2f}%")
    return df

# 2. PREPROCESARE
def preprocesare_date(df):
    # EliminÄƒm coloane non-numerice sau de identificare
    cols_to_drop = [
        "transaction_id",
        "user_id",
        "merchant_id",
        "country",
        "channel",
        "datetime",
        "Time",          # dacÄƒ nu vrei Time Ã®n features
        "Unnamed: 0",
    ]
    X = df.drop(["is_fraud"] + cols_to_drop, axis=1, errors="ignore")
    y = df["is_fraud"]

    print(f"Features folosite pentru antrenare: {list(X.columns)}")

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Ne asigurÄƒm cÄƒ scaler-ul È™tie numele coloanelor
    if not hasattr(scaler, "feature_names_in_"):
        scaler.feature_names_in_ = np.array(X.columns)

    return X_scaled, y, scaler

# 3. ANTRENARE MODEL
def antreneaza_model():
    print("--- Ãncepere Proces Antrenare (Date Sintetice Extinse) ---")

    try:
        df = incarca_date()
    except Exception as e:
        print(e)
        return

    X, y, scaler = preprocesare_date(df)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    print("ğŸš€ IniÈ›ializare Random Forest...")
    model = RandomForestClassifier(
        n_estimators=120,
        max_depth=12,
        random_state=42,
        class_weight="balanced",
        n_jobs=-1,
    )

    print("â³ Se antreneazÄƒ modelul...")
    model.fit(X_train, y_train)

    print("\n--- Rezultate Evaluare (Test) ---")
    y_pred = model.predict(X_test)
    print("Matrice de confuzie:")
    print(confusion_matrix(y_test, y_pred))
    print("\nRaport detaliat:")
    print(classification_report(y_test, y_pred))

    if not os.path.exists(MODELS_DIR):
        os.makedirs(MODELS_DIR)

    model_save_path = os.path.join(MODELS_DIR, "fraud_model.pkl")
    scaler_save_path = os.path.join(MODELS_DIR, "scaler.pkl")

    joblib.dump(model, model_save_path)
    joblib.dump(scaler, scaler_save_path)
    print(f"\nâœ… Model salvat Ã®n: {model_save_path}")
    print(f"âœ… Scaler salvat Ã®n: {scaler_save_path}")

if __name__ == "__main__":
    antreneaza_model()
